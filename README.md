<p align="center">
  <img src="assets/banner.png" alt="EchoCanvas Banner" width="800"/>
</p>

<h1 align="center">ğŸ¨ EchoCanvas: Real-Time Speech-to-Image Generator</h1>
<p align="center">
  <i>Transform your voice into visuals â€” because imagination starts with words.</i><br>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Streamlit-App-red?style=flat-square&logo=streamlit">
  <img src="https://img.shields.io/badge/Python-3.10+-blue?style=flat-square&logo=python">
  <img src="https://img.shields.io/badge/OpenAI-Whisper-green?style=flat-square&logo=openai">
  <img src="https://img.shields.io/badge/License-MIT-yellow?style=flat-square">
</p>

---

## ğŸ§  Overview

**EchoCanvas** is a **real-time Speech-to-Image Generation System** powered by **Deep Learning**.  
It listens to your voice, understands what you say, analyzes your sentiment, and brings your words to life as vivid AI-generated images â€” all within seconds.

Built with **Python** and **Streamlit**, the project integrates **OpenAIâ€™s Whisper** for speech-to-text conversion, a **sentiment analysis model** for emotion detection, and **Stable Diffusion** for text-to-image generation.

---

## ğŸš€ Features

âœ… **ğŸ™ï¸ Speech Recognition** â€“ Record your voice in real-time using your microphone.  
âœ… **ğŸ§¾ Audio Transcription** â€“ Converts speech into text using **Whisper**, a state-of-the-art speech recognition model.  
âœ… **ğŸ’¬ Sentiment Analysis** â€“ Understands the tone (Positive, Neutral, or Negative) of your spoken sentence.  
âœ… **ğŸ–¼ï¸ AI Image Generation** â€“ Uses **Stable Diffusion** to visualize your words into an image (for positive or neutral tones).  
âœ… **âš¡ Real-Time Interaction** â€“ Generates results instantly through a simple and elegant **Streamlit web interface**.  
âœ… **ğŸ’¾ Audio Saving & Replay** â€“ Your audio is automatically saved as a `.wav` file for reuse or testing.  
âœ… **ğŸ§© Modular Design** â€“ Whisper, sentiment analysis, and Stable Diffusion modules are decoupled for flexibility and easy upgrades.

---

## ğŸ” System Workflow

### Step-by-Step Flow:
1. **Record Audio**  
   - User selects duration and records audio via microphone using `sounddevice`.  
   - Audio is saved as `recording.wav`.

2. **Speech-to-Text (Whisper)**  
   - The audio is transcribed using the **Whisper model** into human-readable text.

3. **Sentiment Detection**  
   - The transcription is analyzed by a **sentiment analysis model** to detect its tone: *Positive*, *Neutral*, or *Negative*.

4. **AI Image Generation (Stable Diffusion)**  
   - If the tone is *Positive* or *Neutral*, the text prompt is fed to **Stable Diffusion** to create a matching image.  
   - If *Negative*, the image generation is skipped, and the user is notified.

5. **Output Display**  
   - The **transcription**, **sentiment result**, and **generated image** (if any) are displayed together.

---

## ğŸ§­ Flowchart

```mermaid
graph TD
    A[Start App] --> B[Set Recording Duration]
    B --> C[Record Audio ğŸ™ï¸]
    C --> D[Save as recording.wav]
    D --> E[Transcribe using Whisper]
    E --> F[Analyze Sentiment]
    F -->|Positive/Neutral| G[Generate Image with Stable Diffusion]
    F -->|Negative| H[Skip Image Generation]
    G --> I[Display Text + Sentiment + Image]
    H --> J[Display Text + Sentiment Only]
    I --> K[End]
    J --> K[End]
```

---

## ğŸ§© Tech Stack

| Component | Technology Used |
|------------|------------------|
| **Frontend** | Streamlit |
| **Audio Recording** | sounddevice |
| **Speech-to-Text** | OpenAI Whisper |
| **Sentiment Analysis** | Hugging Face Transformers |
| **Image Generation** | Stable Diffusion (Diffusers library) |
| **Backend Language** | Python 3.10+ |
| **Environment** | Virtualenv or Conda |

---

## âš™ï¸ Installation

1. **Clone this repository:**
   ```bash
   git clone https://github.com/PavanKumar1207/Echo-Canvas
   cd EchoCanvas
   ```

2. **Create and activate a virtual environment:**
   ```bash
   python -m venv venv
   venv\Scripts\activate     # On Windows
   source venv/bin/activate  # On macOS/Linux
   ```

3. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

4. **(Optional) Download pre-trained models:**
   - Whisper model: [OpenAI Whisper](https://github.com/openai/whisper)
   - Stable Diffusion: [Hugging Face Diffusers](https://huggingface.co/CompVis/stable-diffusion-v1-4)

---

## â–¶ï¸ How to Run

Start the Streamlit app:
```bash
streamlit run speech_to_image.py
```

Then open the **localhost URL** (usually `http://localhost:8501`) in your browser.

### ğŸ§­ Usage Steps
1. Set your **recording duration**.  
2. Click **ğŸ™ï¸ Start Recording**.  
3. Wait for transcription and sentiment analysis to complete.  
4. If the sentiment is *positive* or *neutral*, an AI-generated image will appear.  
5. Download or view the output image.

---

## ğŸ“ Project Structure

```
EchoCanvas/
â”‚
â”œâ”€â”€ speech_to_image.py        # Main Streamlit app
â”œâ”€â”€ requirements.txt          # All dependencies
â”œâ”€â”€ assets/                   # Optional: images, icons, etc.
â”œâ”€â”€ recordings/               # Saved audio files
â”œâ”€â”€ outputs/                  # Generated AI images
â”œâ”€â”€ README.md                 # Documentation
â””â”€â”€ LICENSE                   # MIT License
```

---

## ğŸ§  Future Enhancements

- ğŸ­ **Emotion-based Style Generation:** Modify image style based on detected emotion (e.g., dark for sad, bright for happy).  
- ğŸ—£ï¸ **Multi-Language Whisper Support:** Extend to other languages like Hindi, Spanish, etc.  
- ğŸ“¡ **Live Stream Support:** Convert live audio streams (e.g., speeches) into visual stories in real-time.  
- ğŸ¤– **Chatbot Integration:** Combine with conversational AI to generate interactive storytelling.  
- ğŸª„ **Fine-tuned Diffusion Model:** Use custom fine-tuned Stable Diffusion models for domain-specific visuals.

---

## ğŸ§° Troubleshooting

| Issue | Possible Fix |
|--------|---------------|
| **CUDA not available** | Install PyTorch with CUDA or fallback to CPU (slower). |
| **Model not loading** | Check model paths and ensure proper Hugging Face authentication. |
| **Audio not recorded** | Verify microphone permissions and device index. |
| **Memory Errors** | Use smaller model versions or enable CPU inference. |

---

## ğŸ¤ Contributing

Contributions are always welcome!  

1. Fork this repo  
2. Create your feature branch (`git checkout -b feature/amazing-feature`)  
3. Commit your changes (`git commit -m 'Add some feature'`)  
4. Push to the branch (`git push origin feature/amazing-feature`)  
5. Open a **Pull Request**

---

## ğŸ“œ License

This project is licensed under the **MIT License** â€” see the [LICENSE](LICENSE) file for details.

---

## ğŸŒŸ Acknowledgements

- [OpenAI Whisper](https://github.com/openai/whisper)
- [Hugging Face Transformers](https://huggingface.co)
- [Stable Diffusion](https://stability.ai/)
- [Streamlit](https://streamlit.io)
- [Diffusers](https://github.com/huggingface/diffusers)

---

## ğŸ’¡ Example Output

| Input (Speech) | Sentiment | Generated Image |
|----------------|------------|-----------------|
| â€œA sunset over a calm ocean.â€ | Positive | ğŸŒ… *(AI-generated ocean sunset)* |
| â€œA person walking through a forest in the rain.â€ | Neutral | ğŸŒ§ï¸ *(AI-generated forest scene)* |
| â€œI feel so sad and lost.â€ | Negative | ğŸš« *(No image generated)* |

---
## ğŸ¤© Support & Stars

<p align="center"> If you find this project interesting, please give it a â­ and share it with others! </p> <p align="center"> <img src="https://img.shields.io/github/stars/PavanKumar1207/Echo-Canvas?style=social"> </p>

---

## ğŸ End of README  
`â€œWhere words meet imagination â€” EchoCanvas turns sound into art.â€`
